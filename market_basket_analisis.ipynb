{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGAR LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'user_id', 'eval_set', 'order_number', 'order_dow',\n",
      "       'order_hour_of_day', 'days_since_prior_order'],\n",
      "      dtype='object')\n",
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered'], dtype='object')\n",
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered'], dtype='object')\n",
      "Index(['product_id', 'product_name', 'aisle_id', 'department_id'], dtype='object')\n",
      "Index(['user_id', 'n_compras', 'last_order_date', 'mean_time_between_orders',\n",
      "       'Segmento'],\n",
      "      dtype='object')\n",
      "Index(['aisle_id', 'aisle'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders  = pd.read_csv(r'data\\orders.csv')\n",
    "order_products_prior = pd.read_csv(r'data\\order_products__prior.csv')\n",
    "order_products_train = pd.read_csv(r'data\\order_products__train.csv')\n",
    "products = pd.read_csv(r'data\\products.csv')\n",
    "aisles = pd.read_csv(r'data\\aisles.csv')\n",
    "user_segmented = pd.read_csv(r'data\\segmented_users.csv')\n",
    "\n",
    "print(orders.columns)\n",
    "print(order_products_prior.columns)\n",
    "print(order_products_train.columns)\n",
    "print(products.columns)\n",
    "print(user_segmented.columns)\n",
    "print(aisles.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HACER UN MERGE DE LOS CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2539329        1    prior             1          2                  8   \n",
      "2   2539329        1    prior             1          2                  8   \n",
      "3   2539329        1    prior             1          2                  8   \n",
      "4   2539329        1    prior             1          2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN         196                  1          0   \n",
      "1                     NaN       14084                  2          0   \n",
      "2                     NaN       12427                  3          0   \n",
      "3                     NaN       26088                  4          0   \n",
      "4                     NaN       26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  \\\n",
      "0                                     Soda        77              7   \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16   \n",
      "2                      Original Beef Jerky        23             19   \n",
      "3               Aged White Cheddar Popcorn        23             19   \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17   \n",
      "\n",
      "             aisle  n_compras  last_order_date  mean_time_between_orders  \\\n",
      "0      soft drinks         11             14.0                 17.272727   \n",
      "1  soy lactosefree         11             14.0                 17.272727   \n",
      "2    popcorn jerky         11             14.0                 17.272727   \n",
      "3    popcorn jerky         11             14.0                 17.272727   \n",
      "4      paper goods         11             14.0                 17.272727   \n",
      "\n",
      "  Segmento  \n",
      "0    Nuevo  \n",
      "1    Nuevo  \n",
      "2    Nuevo  \n",
      "3    Nuevo  \n",
      "4    Nuevo  \n"
     ]
    }
   ],
   "source": [
    "order_products = pd.concat([order_products_prior, order_products_train], ignore_index=True)\n",
    "\n",
    "merged_data = orders.merge(order_products, on=\"order_id\", how=\"inner\")\n",
    "\n",
    "merged_data = merged_data.merge(products, on=\"product_id\", how=\"left\")\n",
    "\n",
    "merged_data = merged_data.merge(aisles, on=\"aisle_id\", how=\"left\")\n",
    "\n",
    "merged_data = merged_data.merge(user_segmented, on=\"user_id\", how=\"left\")\n",
    "\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAR DATAFRAMES POR CADA SEGMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11091264, 18)\n",
      "(5091504, 18)\n",
      "(12656779, 18)\n",
      "(4979559, 18)\n",
      "Index(['order_id', 'user_id', 'eval_set', 'order_number', 'order_dow',\n",
      "       'order_hour_of_day', 'days_since_prior_order', 'product_id',\n",
      "       'add_to_cart_order', 'reordered', 'product_name', 'aisle_id',\n",
      "       'department_id', 'aisle', 'n_compras', 'last_order_date',\n",
      "       'mean_time_between_orders', 'Segmento'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_frecuentes = merged_data.query(\"Segmento == 'Frecuente'\")\n",
    "df_nuevos = merged_data.query(\"Segmento == 'Nuevo'\")\n",
    "df_ocasionales = merged_data.query(\"Segmento == 'Ocasional'\")\n",
    "df_inactivos = merged_data.query(\"Segmento == 'Inactivo'\")\n",
    "\n",
    "# Mostrar un ejemplo\n",
    "print(df_frecuentes.shape)\n",
    "print(df_nuevos.shape)\n",
    "print(df_ocasionales.shape)\n",
    "print(df_inactivos.shape)\n",
    "\n",
    "print(df_frecuentes.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTRAR LOS PRODUCTOS MÁS POPULARES DE CADA SEGMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántas veces aparece cada producto\n",
    "aisle_counts_frecuentes = df_frecuentes['aisle_id'].value_counts()\n",
    "aisle_counts_nuevos = df_nuevos['aisle_id'].value_counts()\n",
    "aisle_counts_ocasionales = df_ocasionales['aisle_id'].value_counts()\n",
    "aisle_counts_inactivos= df_inactivos['aisle_id'].value_counts()\n",
    "\n",
    "# Filtrar aisles que aparecen en al menos 500 compras (puedes ajustar este número)\n",
    "popular_aisle_frecuentes = aisle_counts_frecuentes[aisle_counts_frecuentes > 200].index\n",
    "popular_aisle_nuevos = aisle_counts_nuevos[aisle_counts_nuevos > 200].index\n",
    "popular_aisle_ocasionales = aisle_counts_ocasionales[aisle_counts_ocasionales > 200].index\n",
    "popular_aisle_inactivos= aisle_counts_inactivos[aisle_counts_inactivos > 200].index\n",
    "\n",
    "# Filtrar el dataset para trabajar solo con los productos más comprados\n",
    "order_aisle_filtered_frecuentes = df_frecuentes[df_frecuentes['aisle_id'].isin(popular_aisle_frecuentes)]\n",
    "order_aisle_filtered_nuevos = df_nuevos[df_nuevos['aisle_id'].isin(popular_aisle_nuevos)]\n",
    "order_aisle_filtered_ocasionales = df_ocasionales[df_ocasionales['aisle_id'].isin(popular_aisle_ocasionales)]\n",
    "order_aisle_filtered_inactivos = df_inactivos[df_inactivos['aisle_id'].isin(popular_aisle_inactivos)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMITAR EL NÚMERO DE TRANSACCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una muestra de 500,000 órdenes para reducir memoria\n",
    "sample_orders_frecuentes = order_aisle_filtered_frecuentes['order_id'].sample(n=150000, random_state=42)\n",
    "sample_orders_nuevos = order_aisle_filtered_nuevos['order_id'].sample(n=150000, random_state=42)\n",
    "sample_orders_ocasionales = order_aisle_filtered_ocasionales['order_id'].sample(n=150000, random_state=42)\n",
    "sample_orders_inactivos = order_aisle_filtered_inactivos['order_id'].sample(n=150000, random_state=42)\n",
    "\n",
    "# Filtrar las órdenes en la muestra\n",
    "order_sample_frecuentes = order_aisle_filtered_frecuentes[order_aisle_filtered_frecuentes['order_id'].isin(sample_orders_frecuentes)]\n",
    "order_sample_nuevos = order_aisle_filtered_nuevos[order_aisle_filtered_nuevos['order_id'].isin(sample_orders_nuevos)]\n",
    "order_sample_ocasionales = order_aisle_filtered_ocasionales[order_aisle_filtered_ocasionales['order_id'].isin(sample_orders_ocasionales)]\n",
    "order_sample_inactivos = order_aisle_filtered_inactivos[order_aisle_filtered_inactivos['order_id'].isin(sample_orders_inactivos)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREAR LA MATRIZ DE TRANSACCIONES CON One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Eliminar duplicados\n",
    "order_sample_filtered_frecuentes = order_sample_frecuentes.drop_duplicates(subset=['order_id', 'product_name'])\n",
    "order_sample_filtered_nuevos = order_sample_nuevos.drop_duplicates(subset=['order_id', 'product_name'])\n",
    "order_sample_filtered_ocasionales = order_sample_ocasionales.drop_duplicates(subset=['order_id', 'product_name'])\n",
    "order_sample_filtered_inactivos = order_sample_inactivos.drop_duplicates(subset=['order_id', 'product_name'])\n",
    "\n",
    "# Crear la matriz dispersa (sparse matrix)\n",
    "product_to_id_frecuentes = {product: idx for idx, product in enumerate(order_sample_filtered_frecuentes['product_name'].unique())}\n",
    "product_to_id_nuevos = {product: idx for idx, product in enumerate(order_sample_filtered_nuevos['product_name'].unique())}\n",
    "product_to_id_ocasionales = {product: idx for idx, product in enumerate(order_sample_filtered_ocasionales['product_name'].unique())}\n",
    "product_to_id_inactivos = {product: idx for idx, product in enumerate(order_sample_filtered_inactivos['product_name'].unique())}\n",
    "\n",
    "order_sample_filtered_frecuentes['product_id_num'] = order_sample_filtered_frecuentes['product_name'].map(product_to_id_frecuentes)\n",
    "order_sample_filtered_nuevos['product_id_num'] = order_sample_filtered_nuevos['product_name'].map(product_to_id_nuevos)\n",
    "order_sample_filtered_ocasionales['product_id_num'] = order_sample_filtered_ocasionales['product_name'].map(product_to_id_ocasionales)\n",
    "order_sample_filtered_inactivos['product_id_num'] = order_sample_filtered_inactivos['product_name'].map(product_to_id_inactivos)\n",
    "\n",
    "row_frecuentes = order_sample_filtered_frecuentes['order_id'].astype('category').cat.codes\n",
    "row_nuevos = order_sample_filtered_nuevos['order_id'].astype('category').cat.codes\n",
    "row_ocasionales = order_sample_filtered_ocasionales['order_id'].astype('category').cat.codes\n",
    "row_inactivos = order_sample_filtered_inactivos['order_id'].astype('category').cat.codes\n",
    "\n",
    "col_frecuentes = order_sample_filtered_frecuentes['product_id_num']\n",
    "col_nuevos = order_sample_filtered_nuevos['product_id_num']\n",
    "col_ocasionales = order_sample_filtered_ocasionales['product_id_num']\n",
    "col_inactivos = order_sample_filtered_inactivos['product_id_num']\n",
    "\n",
    "data_frecuentes = [1] * len(order_sample_filtered_frecuentes)\n",
    "data_nuevos = [1] * len(order_sample_filtered_nuevos)\n",
    "data_ocasionales = [1] * len(order_sample_filtered_ocasionales)          \n",
    "data_inactivos = [1] * len(order_sample_filtered_inactivos)\n",
    "\n",
    "# Crear la matriz dispersa\n",
    "basket_sparse_frecuentes = coo_matrix((data_frecuentes, (row_frecuentes, col_frecuentes)), shape=(order_sample_filtered_frecuentes['order_id'].nunique(), len(product_to_id_frecuentes)))\n",
    "basket_sparse_nuevos = coo_matrix((data_nuevos, (row_nuevos, col_nuevos)), shape=(order_sample_filtered_nuevos['order_id'].nunique(), len(product_to_id_nuevos)))\n",
    "basket_sparse_ocasionales = coo_matrix((data_ocasionales, (row_ocasionales, col_ocasionales)), shape=(order_sample_filtered_ocasionales['order_id'].nunique(), len(product_to_id_ocasionales)))\n",
    "basket_sparse_inactivos = coo_matrix((data_inactivos, (row_inactivos, col_inactivos)), shape=(order_sample_filtered_inactivos['order_id'].nunique(), len(product_to_id_inactivos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APLICAR EL ALGORITMO APRIORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cesar\\AppData\\Local\\Temp\\ipykernel_14824\\2499324798.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_df_frecuentes = basket_df_frecuentes.applymap(lambda x: 1 if x > 0 else 0)\n",
      "C:\\Users\\cesar\\AppData\\Local\\Temp\\ipykernel_14824\\2499324798.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_df_nuevos = basket_df_nuevos.applymap(lambda x: 1 if x > 0 else 0)\n",
      "C:\\Users\\cesar\\AppData\\Local\\Temp\\ipykernel_14824\\2499324798.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_df_ocasionales = basket_df_ocasionales.applymap(lambda x: 1 if x > 0 else 0)\n",
      "C:\\Users\\cesar\\AppData\\Local\\Temp\\ipykernel_14824\\2499324798.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_df_inactivos = basket_df_inactivos.applymap(lambda x: 1 if x > 0 else 0)\n",
      "C:\\Users\\cesar\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "C:\\Users\\cesar\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "C:\\Users\\cesar\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "C:\\Users\\cesar\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "basket_df_frecuentes = pd.DataFrame.sparse.from_spmatrix(basket_sparse_frecuentes, columns=product_to_id_frecuentes.keys())\n",
    "basket_df_nuevos = pd.DataFrame.sparse.from_spmatrix(basket_sparse_nuevos, columns=product_to_id_nuevos.keys())\n",
    "basket_df_ocasionales = pd.DataFrame.sparse.from_spmatrix(basket_sparse_ocasionales, columns=product_to_id_ocasionales.keys())\n",
    "basket_df_inactivos = pd.DataFrame.sparse.from_spmatrix(basket_sparse_inactivos, columns=product_to_id_inactivos.keys())\n",
    "\n",
    "# Convertir los valores de la matriz en binarios (1 si el producto fue comprado, 0 si no)\n",
    "basket_df_frecuentes = basket_df_frecuentes.applymap(lambda x: 1 if x > 0 else 0)\n",
    "basket_df_nuevos = basket_df_nuevos.applymap(lambda x: 1 if x > 0 else 0)\n",
    "basket_df_ocasionales = basket_df_ocasionales.applymap(lambda x: 1 if x > 0 else 0)\n",
    "basket_df_inactivos = basket_df_inactivos.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Aplicar Apriori para obtener los conjuntos frecuentes\n",
    "frequent_itemsets_frecuentes = apriori(basket_df_frecuentes, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets_nuevos = apriori(basket_df_nuevos, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets_ocasionales = apriori(basket_df_ocasionales, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets_inactivos = apriori(basket_df_inactivos, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociación\n",
    "rules_frecuentes = association_rules(frequent_itemsets_frecuentes, metric=\"lift\", min_threshold=1)\n",
    "rules_nuevos = association_rules(frequent_itemsets_nuevos, metric=\"lift\", min_threshold=1)\n",
    "rules_ocasionales = association_rules(frequent_itemsets_ocasionales, metric=\"lift\", min_threshold=1)\n",
    "rules_inactivos = association_rules(frequent_itemsets_inactivos, metric=\"lift\", min_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTRAR REGLAS POR LAS MAS CONFIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.25\n",
    "\n",
    "rules_sorted_frecuentes = rules_frecuentes.sort_values(by=['support', 'confidence', 'lift'], ascending=[False, False, False])\n",
    "rules_sorted_nuevos = rules_nuevos.sort_values(by=['support', 'confidence', 'lift'], ascending=[False, False, False])\n",
    "rules_sorted_ocasionales = rules_ocasionales.sort_values(by=['support', 'confidence', 'lift'], ascending=[False, False, False])\n",
    "rules_sorted_inactivos = rules_inactivos.sort_values(by=['support', 'confidence', 'lift'], ascending=[False, False, False])\n",
    "\n",
    "rules_filtered_frecuentes = rules_sorted_frecuentes[rules_sorted_frecuentes['confidence'] > confidence]\n",
    "rules_filtered_nuevos = rules_sorted_nuevos[rules_sorted_nuevos['confidence'] > confidence]\n",
    "rules_filtered_ocasionales = rules_sorted_ocasionales[rules_sorted_ocasionales['confidence'] > confidence]\n",
    "rules_filtered_inactivos = rules_sorted_inactivos[rules_sorted_inactivos['confidence'] > confidence]\n",
    "\n",
    "\n",
    "rules_filtered_frecuentes.to_csv(fr'market_basket_analysis\\filtered_rules_{confidence}_frecuentes.csv',index=False)\n",
    "rules_filtered_nuevos.to_csv(fr'market_basket_analysis\\filtered_rules_{confidence}_nuevos.csv',index=False)\n",
    "rules_filtered_ocasionales.to_csv(fr'market_basket_analysis\\filtered_rules_{confidence}_ocasionales.csv',index=False)\n",
    "rules_filtered_inactivos.to_csv(fr'market_basket_analysis\\filtered_rules_{confidence}_inactivos.csv',index=False)\n",
    "\n",
    "rules_sorted_frecuentes.to_csv(r'market_basket_analysis\\sorted_rules_frecuentes.csv',index=False)\n",
    "rules_sorted_nuevos.to_csv(r'market_basket_analysis\\sorted_rules_nuevos.csv',index=False)\n",
    "rules_sorted_ocasionales.to_csv(r'market_basket_analysis\\sorted_rules_ocasionales.csv',index=False)\n",
    "rules_sorted_inactivos.to_csv(r'market_basket_analysis\\sorted_rules_inactivos.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
